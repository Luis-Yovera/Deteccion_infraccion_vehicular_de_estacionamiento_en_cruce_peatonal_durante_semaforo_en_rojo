{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luis-Yovera/Deteccion_infraccion_vehicular_de_estacionamiento_en_cruce_peatonal_durante_semaforo_en_rojo/blob/TAREAS_U1_PDSeI/Copia_de_Pr%C3%A1ctica_PDSeI_01_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Trabajo 01 PDSeI - Galarreta, Recuenco, Yovera - Mecatrónica VIII UNT"
      ],
      "metadata": {
        "id": "-sfd5y_LexZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalaciones"
      ],
      "metadata": {
        "id": "tQGP2l2Ee2zU"
      }
    },
    {
      "metadata": {
        "id": "PtKvmZx-WmUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91bfbd1a-7d35-4b20-dbab-a1d6192128c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision #Conjuntos de datasets predefinidos y populares como CIFAR10, ImageNet, y COCO. facilitan el procesamiento y la manipulación de imágenes antes de entrenar modelos."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar dependencias"
      ],
      "metadata": {
        "id": "3dr3HMvje_kV"
      }
    },
    {
      "metadata": {
        "id": "bGU6NwlsXFSt"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir Hiperparámetros"
      ],
      "metadata": {
        "id": "RbUo8FmkfFB1"
      }
    },
    {
      "metadata": {
        "id": "_bNfVLRUYqZA"
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 256  # Aumentado de 128 a 256\n",
        "num_classes = 10\n",
        "num_epochs = 20  # Aumentado de 5 a 20\n",
        "batch_size = 64  # Ajustado de 100 a 64\n",
        "lr = 5e-3  # Aumentado de 1e-3 a 5e-3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargando la base de datos mnist"
      ],
      "metadata": {
        "id": "DM48UlJ9gMOE"
      }
    },
    {
      "metadata": {
        "id": "lCsBCXMwbpH5",
        "outputId": "af2f46d6-b726-41a4-ee1d-17e86823f7f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = dsets.FashionMNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)  #Contiene el conjunto de imágenes y etiquetas del conjunto de entrenamiento\n",
        "                                                                              #  Contiene imágenes de prendas de ropa  //   28x28 píxeles\n",
        "test_data = dsets.FashionMNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor()) #Contiene el conjunto de imágenes y etiquetas del conjunto de prueba"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11542677.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 210234.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3876706.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5790366.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leyendo la data"
      ],
      "metadata": {
        "id": "WpMOKBJkhisv"
      }
    },
    {
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "cell_type": "code",
      "source": [
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)            #Es un DataLoader que gestiona los datos de entrenamiento, dividiéndolos en lotes de tamaño batch_size y barajando las muestras aleatoriamente para cada época.\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size,\n",
        "                                      shuffle = False)                  # Es Es un DataLoader que gestiona los datos de prueba, también dividiéndolos en lotes de tamaño batch_size, pero sin barajar los datos."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir modelo"
      ],
      "metadata": {
        "id": "jhaazXo-h9-v"
      }
    },
    {
      "metadata": {
        "id": "fL-YXTvghaz_"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.drop = nn.Dropout(0.1) # Mientras más bajo sea, el modelo podrá retener ayor información\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.drop(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instancia del modelo"
      ],
      "metadata": {
        "id": "uQdjiXCeiNiu"
      }
    },
    {
      "metadata": {
        "id": "-3EPEqbjjfAT"
      },
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, num_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilación"
      ],
      "metadata": {
        "id": "QNgkx4xtipMA"
      }
    },
    {
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "KD3x_O7si_zS"
      }
    },
    {
      "metadata": {
        "id": "u75Xa5VckuTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61dd42d1-a435-474e-88a3-4b9d161e8f2d"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_gen):\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print('Epoca [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "              % (epoch + 1, num_epochs, i + 1, len(train_data) // batch_size, loss.item()))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca [1/20], Step [100/937], Loss: 0.6391\n",
            "Epoca [1/20], Step [200/937], Loss: 0.4794\n",
            "Epoca [1/20], Step [300/937], Loss: 0.4310\n",
            "Epoca [1/20], Step [400/937], Loss: 0.4955\n",
            "Epoca [1/20], Step [500/937], Loss: 0.3971\n",
            "Epoca [1/20], Step [600/937], Loss: 0.4756\n",
            "Epoca [1/20], Step [700/937], Loss: 0.4153\n",
            "Epoca [1/20], Step [800/937], Loss: 0.7596\n",
            "Epoca [1/20], Step [900/937], Loss: 0.5926\n",
            "Epoca [2/20], Step [100/937], Loss: 0.3392\n",
            "Epoca [2/20], Step [200/937], Loss: 0.3953\n",
            "Epoca [2/20], Step [300/937], Loss: 0.2983\n",
            "Epoca [2/20], Step [400/937], Loss: 0.3400\n",
            "Epoca [2/20], Step [500/937], Loss: 0.4548\n",
            "Epoca [2/20], Step [600/937], Loss: 0.6880\n",
            "Epoca [2/20], Step [700/937], Loss: 0.4314\n",
            "Epoca [2/20], Step [800/937], Loss: 0.3329\n",
            "Epoca [2/20], Step [900/937], Loss: 0.3869\n",
            "Epoca [3/20], Step [100/937], Loss: 0.3459\n",
            "Epoca [3/20], Step [200/937], Loss: 0.5057\n",
            "Epoca [3/20], Step [300/937], Loss: 0.4291\n",
            "Epoca [3/20], Step [400/937], Loss: 0.4500\n",
            "Epoca [3/20], Step [500/937], Loss: 0.2913\n",
            "Epoca [3/20], Step [600/937], Loss: 0.4686\n",
            "Epoca [3/20], Step [700/937], Loss: 0.4078\n",
            "Epoca [3/20], Step [800/937], Loss: 0.5540\n",
            "Epoca [3/20], Step [900/937], Loss: 0.2412\n",
            "Epoca [4/20], Step [100/937], Loss: 0.4627\n",
            "Epoca [4/20], Step [200/937], Loss: 0.2137\n",
            "Epoca [4/20], Step [300/937], Loss: 0.2705\n",
            "Epoca [4/20], Step [400/937], Loss: 0.3722\n",
            "Epoca [4/20], Step [500/937], Loss: 0.5122\n",
            "Epoca [4/20], Step [600/937], Loss: 0.4631\n",
            "Epoca [4/20], Step [700/937], Loss: 0.4152\n",
            "Epoca [4/20], Step [800/937], Loss: 0.2782\n",
            "Epoca [4/20], Step [900/937], Loss: 0.2974\n",
            "Epoca [5/20], Step [100/937], Loss: 0.3411\n",
            "Epoca [5/20], Step [200/937], Loss: 0.3519\n",
            "Epoca [5/20], Step [300/937], Loss: 0.2893\n",
            "Epoca [5/20], Step [400/937], Loss: 0.2497\n",
            "Epoca [5/20], Step [500/937], Loss: 0.3818\n",
            "Epoca [5/20], Step [600/937], Loss: 0.5178\n",
            "Epoca [5/20], Step [700/937], Loss: 0.3531\n",
            "Epoca [5/20], Step [800/937], Loss: 0.5537\n",
            "Epoca [5/20], Step [900/937], Loss: 0.3262\n",
            "Epoca [6/20], Step [100/937], Loss: 0.3388\n",
            "Epoca [6/20], Step [200/937], Loss: 0.3860\n",
            "Epoca [6/20], Step [300/937], Loss: 0.4777\n",
            "Epoca [6/20], Step [400/937], Loss: 0.4566\n",
            "Epoca [6/20], Step [500/937], Loss: 0.4055\n",
            "Epoca [6/20], Step [600/937], Loss: 0.3156\n",
            "Epoca [6/20], Step [700/937], Loss: 0.3172\n",
            "Epoca [6/20], Step [800/937], Loss: 0.3888\n",
            "Epoca [6/20], Step [900/937], Loss: 0.4398\n",
            "Epoca [7/20], Step [100/937], Loss: 0.2123\n",
            "Epoca [7/20], Step [200/937], Loss: 0.5303\n",
            "Epoca [7/20], Step [300/937], Loss: 0.2786\n",
            "Epoca [7/20], Step [400/937], Loss: 0.3345\n",
            "Epoca [7/20], Step [500/937], Loss: 0.2591\n",
            "Epoca [7/20], Step [600/937], Loss: 0.1880\n",
            "Epoca [7/20], Step [700/937], Loss: 0.2740\n",
            "Epoca [7/20], Step [800/937], Loss: 0.4282\n",
            "Epoca [7/20], Step [900/937], Loss: 0.2513\n",
            "Epoca [8/20], Step [100/937], Loss: 0.3877\n",
            "Epoca [8/20], Step [200/937], Loss: 0.3368\n",
            "Epoca [8/20], Step [300/937], Loss: 0.2646\n",
            "Epoca [8/20], Step [400/937], Loss: 0.1846\n",
            "Epoca [8/20], Step [500/937], Loss: 0.2267\n",
            "Epoca [8/20], Step [600/937], Loss: 0.1356\n",
            "Epoca [8/20], Step [700/937], Loss: 0.2771\n",
            "Epoca [8/20], Step [800/937], Loss: 0.3624\n",
            "Epoca [8/20], Step [900/937], Loss: 0.2779\n",
            "Epoca [9/20], Step [100/937], Loss: 0.2605\n",
            "Epoca [9/20], Step [200/937], Loss: 0.1735\n",
            "Epoca [9/20], Step [300/937], Loss: 0.2822\n",
            "Epoca [9/20], Step [400/937], Loss: 0.6298\n",
            "Epoca [9/20], Step [500/937], Loss: 0.2801\n",
            "Epoca [9/20], Step [600/937], Loss: 0.4033\n",
            "Epoca [9/20], Step [700/937], Loss: 0.0762\n",
            "Epoca [9/20], Step [800/937], Loss: 0.2411\n",
            "Epoca [9/20], Step [900/937], Loss: 0.3594\n",
            "Epoca [10/20], Step [100/937], Loss: 0.2339\n",
            "Epoca [10/20], Step [200/937], Loss: 0.3825\n",
            "Epoca [10/20], Step [300/937], Loss: 0.2232\n",
            "Epoca [10/20], Step [400/937], Loss: 0.2061\n",
            "Epoca [10/20], Step [500/937], Loss: 0.2920\n",
            "Epoca [10/20], Step [600/937], Loss: 0.2056\n",
            "Epoca [10/20], Step [700/937], Loss: 0.3505\n",
            "Epoca [10/20], Step [800/937], Loss: 0.1527\n",
            "Epoca [10/20], Step [900/937], Loss: 0.2349\n",
            "Epoca [11/20], Step [100/937], Loss: 0.2316\n",
            "Epoca [11/20], Step [200/937], Loss: 0.1816\n",
            "Epoca [11/20], Step [300/937], Loss: 0.2270\n",
            "Epoca [11/20], Step [400/937], Loss: 0.2340\n",
            "Epoca [11/20], Step [500/937], Loss: 0.2290\n",
            "Epoca [11/20], Step [600/937], Loss: 0.4029\n",
            "Epoca [11/20], Step [700/937], Loss: 0.2512\n",
            "Epoca [11/20], Step [800/937], Loss: 0.2152\n",
            "Epoca [11/20], Step [900/937], Loss: 0.3445\n",
            "Epoca [12/20], Step [100/937], Loss: 0.4009\n",
            "Epoca [12/20], Step [200/937], Loss: 0.2346\n",
            "Epoca [12/20], Step [300/937], Loss: 0.2618\n",
            "Epoca [12/20], Step [400/937], Loss: 0.2243\n",
            "Epoca [12/20], Step [500/937], Loss: 0.3857\n",
            "Epoca [12/20], Step [600/937], Loss: 0.3504\n",
            "Epoca [12/20], Step [700/937], Loss: 0.2914\n",
            "Epoca [12/20], Step [800/937], Loss: 0.3300\n",
            "Epoca [12/20], Step [900/937], Loss: 0.3222\n",
            "Epoca [13/20], Step [100/937], Loss: 0.4149\n",
            "Epoca [13/20], Step [200/937], Loss: 0.2798\n",
            "Epoca [13/20], Step [300/937], Loss: 0.5038\n",
            "Epoca [13/20], Step [400/937], Loss: 0.3769\n",
            "Epoca [13/20], Step [500/937], Loss: 0.1095\n",
            "Epoca [13/20], Step [600/937], Loss: 0.2700\n",
            "Epoca [13/20], Step [700/937], Loss: 0.4052\n",
            "Epoca [13/20], Step [800/937], Loss: 0.2351\n",
            "Epoca [13/20], Step [900/937], Loss: 0.2212\n",
            "Epoca [14/20], Step [100/937], Loss: 0.2974\n",
            "Epoca [14/20], Step [200/937], Loss: 0.2749\n",
            "Epoca [14/20], Step [300/937], Loss: 0.2216\n",
            "Epoca [14/20], Step [400/937], Loss: 0.3601\n",
            "Epoca [14/20], Step [500/937], Loss: 0.3075\n",
            "Epoca [14/20], Step [600/937], Loss: 0.2159\n",
            "Epoca [14/20], Step [700/937], Loss: 0.0945\n",
            "Epoca [14/20], Step [800/937], Loss: 0.2326\n",
            "Epoca [14/20], Step [900/937], Loss: 0.2038\n",
            "Epoca [15/20], Step [100/937], Loss: 0.4748\n",
            "Epoca [15/20], Step [200/937], Loss: 0.4172\n",
            "Epoca [15/20], Step [300/937], Loss: 0.1631\n",
            "Epoca [15/20], Step [400/937], Loss: 0.3590\n",
            "Epoca [15/20], Step [500/937], Loss: 0.4789\n",
            "Epoca [15/20], Step [600/937], Loss: 0.2455\n",
            "Epoca [15/20], Step [700/937], Loss: 0.2261\n",
            "Epoca [15/20], Step [800/937], Loss: 0.1582\n",
            "Epoca [15/20], Step [900/937], Loss: 0.2606\n",
            "Epoca [16/20], Step [100/937], Loss: 0.2460\n",
            "Epoca [16/20], Step [200/937], Loss: 0.3177\n",
            "Epoca [16/20], Step [300/937], Loss: 0.2415\n",
            "Epoca [16/20], Step [400/937], Loss: 0.3098\n",
            "Epoca [16/20], Step [500/937], Loss: 0.2816\n",
            "Epoca [16/20], Step [600/937], Loss: 0.5043\n",
            "Epoca [16/20], Step [700/937], Loss: 0.2847\n",
            "Epoca [16/20], Step [800/937], Loss: 0.1343\n",
            "Epoca [16/20], Step [900/937], Loss: 0.3417\n",
            "Epoca [17/20], Step [100/937], Loss: 0.1427\n",
            "Epoca [17/20], Step [200/937], Loss: 0.3877\n",
            "Epoca [17/20], Step [300/937], Loss: 0.3003\n",
            "Epoca [17/20], Step [400/937], Loss: 0.5070\n",
            "Epoca [17/20], Step [500/937], Loss: 0.3188\n",
            "Epoca [17/20], Step [600/937], Loss: 0.2055\n",
            "Epoca [17/20], Step [700/937], Loss: 0.3262\n",
            "Epoca [17/20], Step [800/937], Loss: 0.2570\n",
            "Epoca [17/20], Step [900/937], Loss: 0.2625\n",
            "Epoca [18/20], Step [100/937], Loss: 0.2830\n",
            "Epoca [18/20], Step [200/937], Loss: 0.1400\n",
            "Epoca [18/20], Step [300/937], Loss: 0.1761\n",
            "Epoca [18/20], Step [400/937], Loss: 0.1520\n",
            "Epoca [18/20], Step [500/937], Loss: 0.3731\n",
            "Epoca [18/20], Step [600/937], Loss: 0.2893\n",
            "Epoca [18/20], Step [700/937], Loss: 0.3513\n",
            "Epoca [18/20], Step [800/937], Loss: 0.4590\n",
            "Epoca [18/20], Step [900/937], Loss: 0.1919\n",
            "Epoca [19/20], Step [100/937], Loss: 0.2743\n",
            "Epoca [19/20], Step [200/937], Loss: 0.3130\n",
            "Epoca [19/20], Step [300/937], Loss: 0.1875\n",
            "Epoca [19/20], Step [400/937], Loss: 0.2939\n",
            "Epoca [19/20], Step [500/937], Loss: 0.2432\n",
            "Epoca [19/20], Step [600/937], Loss: 0.1335\n",
            "Epoca [19/20], Step [700/937], Loss: 0.2905\n",
            "Epoca [19/20], Step [800/937], Loss: 0.5101\n",
            "Epoca [19/20], Step [900/937], Loss: 0.3326\n",
            "Epoca [20/20], Step [100/937], Loss: 0.2526\n",
            "Epoca [20/20], Step [200/937], Loss: 0.1831\n",
            "Epoca [20/20], Step [300/937], Loss: 0.2807\n",
            "Epoca [20/20], Step [400/937], Loss: 0.2085\n",
            "Epoca [20/20], Step [500/937], Loss: 0.2775\n",
            "Epoca [20/20], Step [600/937], Loss: 0.1743\n",
            "Epoca [20/20], Step [700/937], Loss: 0.2810\n",
            "Epoca [20/20], Step [800/937], Loss: 0.1674\n",
            "Epoca [20/20], Step [900/937], Loss: 0.3149\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DTPvMW5jHB9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb15ba4-1833-40d0-a2b2-004d5cb9107b"
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_gen:\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    output = net(images)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "\n",
        "print('Accuracy: %.3f %%' % (100 * correct / (total + 1)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.861 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1NojkXHle9d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}